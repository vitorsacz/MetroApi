{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#requisitando a pagina html\n",
    "def get_page_html(url):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        if page.status_code == 200:\n",
    "            return page.text\n",
    "        else:\n",
    "            return None\n",
    "    except BaseException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_home = get_page_html(\"https://www.viaquatro.com.br/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES_METRO = ['azul', 'verde', 'vermelha', 'amarela', 'lilás', 'prata']\n",
    "\n",
    "LINES_CPTM = [\n",
    "    'rubi',\n",
    "    'diamante',\n",
    "    'esmeralda',\n",
    "    'turquesa',\n",
    "    'coral',\n",
    "    'safira',\n",
    "    'jade']\n",
    "\n",
    "ALL_LINES = LINES_METRO + LINES_CPTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def get_operation_status(soup, all_lines):\n",
    "\n",
    "    extracted_status = {line: '' for line in all_lines}\n",
    "\n",
    "    # Contem todas as informações necessárias\n",
    "    status_column = soup.find(class_=\"operacao\")\n",
    "\n",
    "    # A linha 'amarela'está contida em um container especial\n",
    "    extracted_status['amarela'] = status_column.find(class_=\"status\").text\n",
    "\n",
    "    #Todas as outras linhas são mostradas de uma forma mais ordenada. Metro tem uma\n",
    "    # div e CPTM possui outra\n",
    "    lines_containers = status_column.find_all(class_=\"linhas\")\n",
    "\n",
    "    for container in lines_containers:\n",
    "        line_info_divs = container.find_all(class_=\"info\")\n",
    "\n",
    "        #Cada informação nas div tem 2 tags span: uma para o título e outra \n",
    "        # o status da linha\n",
    "        for div in line_info_divs:\n",
    "            line_title = ''\n",
    "            line_status = ''\n",
    "            spans = div.find_all(\"span\")\n",
    "            line_title = spans[0].text.lower()\n",
    "            line_status = spans[1].text.lower()\n",
    "\n",
    "            # Agora temos o titulo e a linha setadas, é preciso \n",
    "            # guardar para utilizar depois\n",
    "            \n",
    "            extracted_status[line_title] = line_status\n",
    "        logging.info('Extracted: {}'.format(extracted_status))\n",
    "\n",
    "    \n",
    "    return(extracted_status)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_data(soup):\n",
    "    return soup.find('time').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrapper_status(vq_home, ALL_LINES):\n",
    "\n",
    "    soup = BeautifulSoup(vq_home, 'html.parser' )\n",
    "    # time_data = get_time_data(soup)\n",
    "    op_status = get_operation_status(soup, ALL_LINES)\n",
    "\n",
    "    status_linhas = {}\n",
    "\n",
    "    for line in ALL_LINES:\n",
    "\n",
    "        status_linhas[line] = op_status[line]\n",
    "        print([line, op_status[line]])\n",
    "\n",
    "    print(status_linhas)\n",
    "    return status_linhas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azul', 'dados indisponíveis']\n",
      "['verde', 'dados indisponíveis']\n",
      "['vermelha', 'dados indisponíveis']\n",
      "['amarela', 'normal']\n",
      "['lilás', 'normal']\n",
      "['prata', 'dados indisponíveis']\n",
      "['rubi', 'normal']\n",
      "['diamante', 'circulação de trens']\n",
      "['esmeralda', 'normal']\n",
      "['turquesa', 'normal']\n",
      "['coral', 'normal']\n",
      "['safira', 'normal']\n",
      "['jade', 'normal']\n",
      "{'azul': 'dados indisponíveis', 'verde': 'dados indisponíveis', 'vermelha': 'dados indisponíveis', 'amarela': 'normal', 'lilás': 'normal', 'prata': 'dados indisponíveis', 'rubi': 'normal', 'diamante': 'circulação de trens', 'esmeralda': 'normal', 'turquesa': 'normal', 'coral': 'normal', 'safira': 'normal', 'jade': 'normal'}\n",
      "\n",
      "\n",
      "testando aqui\n"
     ]
    }
   ],
   "source": [
    "vq_home = get_page_html(\"https://www.viaquatro.com.br/\")\n",
    "\n",
    "scrapper_status(vq_home, ALL_LINES)\n",
    "\n",
    "print(\"\\n\\ntestando aqui\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def scrapper_status(vq_home, ALL_LINES):\n",
    "\n",
    "    soup = BeautifulSoup(vq_home, 'html.parser' )\n",
    "    # time_data = get_time_data(soup)\n",
    "    op_status = get_operation_status(soup, ALL_LINES)\n",
    "\n",
    "    status_linhas = {}\n",
    "\n",
    "    for line in ALL_LINES:\n",
    "        status_linhas[line] = op_status[line]\n",
    "        print([line, op_status[line]])\n",
    "\n",
    "    # Converter o dicionário status_linhas para o formato JSON\n",
    "    json_data = json.dumps(status_linhas)  # Usar json.dumps para converter\n",
    "\n",
    "    print(json_data)\n",
    "\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azul', 'dados indisponíveis']\n",
      "['verde', 'dados indisponíveis']\n",
      "['vermelha', 'dados indisponíveis']\n",
      "['amarela', 'normal']\n",
      "['lilás', 'normal']\n",
      "['prata', 'dados indisponíveis']\n",
      "['rubi', 'normal']\n",
      "['diamante', 'circulação de trens']\n",
      "['esmeralda', 'normal']\n",
      "['turquesa', 'normal']\n",
      "['coral', 'normal']\n",
      "['safira', 'normal']\n",
      "['jade', 'normal']\n",
      "{\"azul\": \"dados indispon\\u00edveis\", \"verde\": \"dados indispon\\u00edveis\", \"vermelha\": \"dados indispon\\u00edveis\", \"amarela\": \"normal\", \"lil\\u00e1s\": \"normal\", \"prata\": \"dados indispon\\u00edveis\", \"rubi\": \"normal\", \"diamante\": \"circula\\u00e7\\u00e3o de trens\", \"esmeralda\": \"normal\", \"turquesa\": \"normal\", \"coral\": \"normal\", \"safira\": \"normal\", \"jade\": \"normal\"}\n",
      "\n",
      "\n",
      "testando aqui\n",
      "{\"azul\": \"dados indispon\\u00edveis\", \"verde\": \"dados indispon\\u00edveis\", \"vermelha\": \"dados indispon\\u00edveis\", \"amarela\": \"normal\", \"lil\\u00e1s\": \"normal\", \"prata\": \"dados indispon\\u00edveis\", \"rubi\": \"normal\", \"diamante\": \"circula\\u00e7\\u00e3o de trens\", \"esmeralda\": \"normal\", \"turquesa\": \"normal\", \"coral\": \"normal\", \"safira\": \"normal\", \"jade\": \"normal\"}\n"
     ]
    }
   ],
   "source": [
    "vq_home = get_page_html(\"https://www.viaquatro.com.br/\")\n",
    "\n",
    "status = scrapper_status(vq_home, ALL_LINES)\n",
    "\n",
    "print(\"\\n\\ntestando aqui\")\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
